`LinearRegression` — это класс в библиотеке [[sklearn]], который реализует линейную регрессию. **Линейная регрессия** — это метод статистического моделирования, который используется для предсказания непрерывных значений на основе линейной комбинации признаков.


### Параметры

- **fit_intercept**: Булево значение, определяющее, нужно ли вычислять свободный член (intercept) в модели. По умолчанию `True`.
    
- **normalize**: Булево значение, указывающее, нужно ли нормализовать данные перед применением модели. По умолчанию `False`.
    
- **copy_X**: Булево значение, указывающее, нужно ли копировать матрицу признаков `X`. По умолчанию `True`.
    
- **n_jobs**: Количество параллельных задач, которые будут использоваться для вычислений. По умолчанию `None`, что означает использование одного ядра.

### Методы

- **fit(X, y)**: Обучает модель на данных `X` и целевых значениях `y`.
    
- **predict(X)**: Предсказывает значения на основе обученной модели.
    
- **score(X, y)**: Возвращает коэффициент детерминации R2R2 модели на данных `X` и целевых значениях `y`.
### Пример вывода

Для примера выше, вывод может выглядеть так:

```python
Среднеквадратичная ошибка: 0.00
Коэффициенты: [0.8]
Свободный член: 2.2
```

### Интерпретация результатов

- **Коэффициенты**: Коэффициенты модели, которые умножаются на соответствующие признаки. В данном случае, коэффициент равен 0.8, что означает, что при увеличении признака на 1, предсказанное значение увеличивается на 0.8.
    
- **Свободный член**: Свободный член (intercept) модели, который добавляется к предсказанным значениям. В данном случае, свободный член равен 2.2.
    
- **Среднеквадратичная ошибка**: Метрика, которая показывает, насколько предсказанные значения отличаются от фактических. Чем меньше значение, тем лучше модель.

### Метрики

Для регрессионных задач наиболее часто используются следующие три метрики:

**Средняя абсолютная ошибка - Mean Absolute Error** (MAE) - усредняет абсолютные значения ошибок:

  

$$\frac 1n\sum_{i=1}^n|y_i-\hat{y}_i|$$

  

**Среднеквадратическая ошибка - Mean Squared Error** (MSE) - усредняет квадраты ошибок:

  
$$\frac 1n\sum_{i=1}^n(y_i-\hat{y}_i)^2$$

  
**Среднеквадратическое отклонение - Root Mean Squared Error** (RMSE) - квадратный корень от среднеквадратической ошибки:

  
$$\sqrt{\frac 1n\sum_{i=1}^n(y_i-\hat{y}_i)^2}$$


Сравнение метрик:

- **MAE** проще всего понять - это просто средняя ошибка.

- **MSE** более популярнее MAE, потому что MSE больше "наказывает" большие ошибки, и обычно это более полезно в прикладных задачах.

- **RMSE** даже ещё более популярна, чем MSE, потому что RMSE измеряется в тех же единицах, что и "y".

  
Все эти метрики являются **функциями потери (loss functions)**, потому что мы стремимся уменьшить их.


### Пример кода:
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error

MAE = mean_absolute_error(y_test, test_pred)
MSE = mean_squared_error(y_test, test_pred)
RMSE = np.sqrt(MSE)
```
### Итог

`LinearRegression` — это простой и мощный инструмент для решения задач линейной регрессии. Он позволяет быстро обучать модели и предсказывать значения на основе линейной комбинации признаков. Благодаря своей простоте и интерпретируемости, линейная регрессия часто используется как первый шаг в анализе данных и построении моделей.